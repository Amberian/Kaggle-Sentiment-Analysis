{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer#词干提取\n",
    "from nltk.stem import WordNetLemmatizer#词形还原\n",
    "from nltk import sent_tokenize#英语句子切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddp\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\ddp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10090, 300)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入模型\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"model/300features_40minwords_10context\")\n",
    "model.wv.syn0.shape#词汇表，在word2vec中每个词的特征向量，词向量维度为之前定义的300，一共是10090个词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['queen'][:10]#取出一个词的词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.doesnt_match('chair desk bed apple'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据\n",
    "train_data=pd.read_csv('data/labeledTrainData.tsv',header=0, delimiter='\\t', quoting=3)\n",
    "test_data=pd.read_csv('data/testData.tsv',header=0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 获得每个review的词向量+随机森林\n",
    "一个文本的词向量=其中每个词的词向量取平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2wordlist(raw_txt, remove_stop):#把一个文本进行预处理并转成词的list\n",
    "    l_stem=LancasterStemmer()#不能用PorterStemmer，对于一些未登录词会报错，比如OED\n",
    "    w_lem=WordNetLemmatizer()\n",
    "    txt=BeautifulSoup(raw_txt,'lxml')\n",
    "    txt=txt.get_text().lower()\n",
    "    txt=re.sub('[^a-zA-Z]',' ',txt)\n",
    "    word=word_tokenize(txt)\n",
    "    if remove_stop:\n",
    "        stops=set(stopwords.words('english'))\n",
    "        word=[w for w in word if w not in stops]\n",
    "    word=[l_stem.stem(w) for w in word]\n",
    "    word=[w_lem.lemmatize(w) for w in word]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def Review_Vec(review_wordlist, model, num_feature):\n",
    "    AFeatureVec=np.zeros((num_feature),dtype='float32')\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    nword=0\n",
    "    for w in review_wordlist:\n",
    "        if w in index2word_set:\n",
    "            nword+=1\n",
    "            AFeatureVec=np.add(AFeatureVec,model[w])\n",
    "    AFeatureVec=np.divide(AFeatureVec,nword)\n",
    "    return AFeatureVec\n",
    "def Avg_Review_Vecs(reviews_wordlists,model, num_feature):\n",
    "    ReviewFeatureVec=np.zeros((len(reviews_wordlists),num_feature),dtype='float32')\n",
    "    for i in range(len(reviews_wordlists)):\n",
    "        if(i%1000==0):\n",
    "            print(\"%d review of %d\"%(i,len(reviews_wordlists)))\n",
    "        ReviewFeatureVec[i]=Review_Vec(reviews_wordlists[i],model,num_feature)\n",
    "    return ReviewFeatureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec中的参数\n",
    "num_worker=4#并行的线程数\n",
    "num_feature=300#词向量的维度\n",
    "num_min_count=40#最小词频，小于这个词频的就不纳入分析\n",
    "num_window=10#上下文窗口大小\n",
    "num_downsample=1e-3#高频词汇的随机降采样的配置阈值，默认为1e-3，范围是(0,1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_reviews=[txt2wordlist(review,True) for review in train_data['review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs=Avg_Review_Vecs(clean_train_reviews,model,num_feature)\n",
    "train_vecs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_reviews=[txt2wordlist(review,True) for review in test_data['review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vecs=Avg_Review_Vecs(clean_test_reviews,model,num_feature)\n",
    "test_vecs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用随机森林(、极端随机森林、梯度提升)预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "forest = forest.fit(train_vecs,train_data['sentiment'])\n",
    "result=forest.predict(test_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame( data={\"id\":test_data[\"id\"], \"sentiment\":result} )\n",
    "output.to_csv( \"data/result/Word2Vec_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 对review聚类\n",
    "使用kmeans，对所有word2vec中的词进行聚类，使得每一个词都有一个对应的类然后对所有review使用kmeans聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1009"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv.syn0\n",
    "num_clusters = word_vectors.shape[0]//10#设定词的聚类中心数目，=word2vec中词汇表的行数/5，即词的数目/5，\n",
    "num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time: 90\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "start=time.time()#用以记录运行时间\n",
    "kmeans=KMeans(n_clusters=num_clusters,n_jobs=-2)#n_jobs=-2：除了一个cpu之外的所有cpu都被使用\n",
    "idx=kmeans.fit_predict(word_vectors)#返回各个词所被分配的类索引\n",
    "end=time.time()\n",
    "run_time=end-start\n",
    "print(\"run time: %d\"%(run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10090,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将word2vec中每个词和上述生成的每个词的类别做成字典形式，从而可以直观的看到哪些词被分到了哪一类里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idx=dict(zip(model.wv.index2word,idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(word_idx.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Cluster %d:\"%(i))\n",
    "    c=[w for w in model.wv.index2word if(word_idx[w]==i)]\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将每个评论转换成这1009个类别的词向量，从而得到一个25000X1009大小的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Review_Class_Vec(review,model, word_idx):\n",
    "    review_vec=np.zeros((num_clusters),dtype='float32')\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for w in review:\n",
    "        if w in index2word_set:\n",
    "            review_vec[word_idx[w]]=np.add(review_vec[word_idx[w]],1)\n",
    "    return review_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Review_Class_Vecs(reviews,model, word_idx):\n",
    "    review_vecs=np.zeros((len(reviews),num_clusters),dtype='float32')\n",
    "    for i in range(len(reviews)):\n",
    "        review_vecs[i]=Review_Class_Vec(reviews[i],model, word_idx)\n",
    "    return review_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_vecs=Review_Class_Vecs(clean_train_reviews,model, word_idx)\n",
    "test_class_vecs=Review_Class_Vecs(clean_test_reviews,model, word_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用随机森林(、极端随机森林、梯度提升)预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "#forest = RandomForestClassifier(n_estimators = 100) \n",
    "forest = GradientBoostingClassifier(n_estimators = 100) \n",
    "forest = forest.fit(train_class_vecs,train_data['sentiment'])\n",
    "result=forest.predict(test_class_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame( data={\"id\":test_data[\"id\"], \"sentiment\":result} )\n",
    "#output.to_csv( \"data/result/Word2Vec_Kmeans_model.csv\", index=False, quoting=3 )\n",
    "output.to_csv( \"data/result/Word2Vec_Kmeans_GBC_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
